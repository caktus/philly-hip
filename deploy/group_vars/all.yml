---

# ----------------------------------------------------------------------------
# Global: Common configuration variables for all inventory groups
# ----------------------------------------------------------------------------

app_name: hip
# we use hip in some places and philly-hip in some places, so let's create a variable
long_app_name: "philly-{{ app_name }}"
aws_region: us-east-1
stack_name: "{{ long_app_name }}-stack"
aws_profile: "{{ long_app_name }}"
cluster_name: "{{ stack_name }}-cluster"

# CloudFormation Outputs
# These values are taken from the CF 'Output' tab


RepositoryURL: 061553509755.dkr.ecr.us-east-1.amazonaws.com/philly-hip-stack-applicationrepository-kk92mehevd86

# The RDS superuser password
admin_database_password: !vault |
  $ANSIBLE_VAULT;1.1;AES256
  63666133363834643339373132356631656633343463313761376363613138383035353532346236
  3162396136333434303539346435306361336636636232620a353139306565616231303763646366
  31636366666262323933643061626135346663646564656534313437393063396633626332663831
  3565323636626163320a633963393664626563313265363632633161643833626366373265643835
  30383637393636336335303231653434666536623535313439646136663239383139323533613239
  6666643563326336613864366161623264363331656632333761

# ----------------------------------------------------------------------------
# caktus.aws-web-stacks: Ansible role to automate AWS CloudFormation stack
#                        provisioning with aws-web-stacks.
# ----------------------------------------------------------------------------

cloudformation_stack:
  profile: "{{ aws_profile }}"
  region: "{{ aws_region }}"
  stack_name: "{{ stack_name }}"
  template_bucket: "aws-web-stacks-{{ app_name }}"
  template_local_path: '{{ playbook_dir + "/stack/eks-no-nat.yml" }}'
  create_changeset: true
  termination_protection: true

  template_parameters:
    UseAES256Encryption: "true"
    CustomerManagedCmkArn: ""
    DomainName: "{{ app_name }}-prod.caktus-built.com"
    DomainNameAlternates: ""
    PrimaryAZ: "{{ aws_region }}a"
    SecondaryAZ: "{{ aws_region }}b"
    DesiredScale: 2
    MaxScale: 4
    ContainerInstanceType: t3a.medium
    AssetsBucketAccessControl: Private
    AssetsUseCloudFront: "false"
    DatabaseClass: db.t3.small
    DatabaseEngineVersion: "11"
    DatabaseParameterGroupFamily: postgres11
    DatabaseName: "{{ app_name }}"
    DatabaseUser: "{{ app_name }}_admin"
    DatabasePassword: "{{ admin_database_password }}"
    DatabaseMultiAZ: "true"
  tags:
    Environment: "{{ app_name }}"

# --------------------------------------------------------------------------
# caktus.k8s-web-cluster: Configuration variables for the single k8s cluster
# --------------------------------------------------------------------------

k8s_cluster_type: aws
k8s_context: "arn:aws:eks:us-east-1:061553509755:cluster/{{ cluster_name }}"
k8s_ingress_nginx_chart_version: "4.0.19"
k8s_cert_manager_chart_version: "v1.7.2"
k8s_letsencrypt_email: admin@caktusgroup.com
k8s_iam_users: [noop]  # https://github.com/caktus/ansible-role-k8s-web-cluster/issues/17
# aws-for-fluent-bit
# - https://github.com/aws/eks-charts/tree/master/stable/aws-for-fluent-bit
# - https://artifacthub.io/packages/helm/aws/aws-for-fluent-bit
k8s_aws_fluent_bit_chart_version: "0.1.18"

# ----------------------------------------------------------------------------
# caktus.django-k8s: Shared configuration variables for staging and production
#                    environments.
# ----------------------------------------------------------------------------

k8s_auth_host: "{{ ClusterEndpoint }}"
k8s_auth_ssl_ca_cert: staging_k8s_auth_ssl_ca_cert.txt
k8s_namespace: hip-staging
k8s_memcached_enabled: true

# App pod configuration:
k8s_container_name: app
k8s_container_port: 8000
k8s_container_image: "{{ RepositoryURL }}"
k8s_container_image_pull_policy: Always
k8s_container_replicas: 2

# Lower resources to preserve Node resources
k8s_container_resources:
    requests:
        memory: "256Mi"
        cpu: "50m"
    limits:
        cpu: "250m"

k8s_migrations_enabled: true
k8s_collectstatic_enabled: false
k8s_container_ingress_annotations:
  nginx.ingress.kubernetes.io/proxy-body-size: 100m
  # These are in seconds, but need to be specified without the trailing 's'
  # usually seen in nginx.conf proper.
  nginx.ingress.kubernetes.io/proxy-connect-timeout: 1800
  nginx.ingress.kubernetes.io/proxy-send-timeout: 1800
  nginx.ingress.kubernetes.io/proxy-read-timeout: 1800
  # Workaround for lack of annotation for send_timeout parameter:
  # https://github.com/kubernetes/ingress-nginx/issues/2441#issuecomment-419714384
  nginx.ingress.kubernetes.io/configuration-snippet: |
    send_timeout 1800s;

# Shared environment variables:
env_database_url: "postgres://{{ app_name }}_{{ env_name }}:{{ database_password }}@{{ DatabaseAddress }}:5432/{{ app_name }}_{{ env_name }}"
env_django_settings: "{{ app_name }}.settings.deploy"
env_cache_host: memcached:11211
env_default_file_storage: "{{ app_name }}.storages.MediaBoto3Storage"
env_media_storage_bucket_name: "{{ app_name }}-{{ env_name }}-philly-private-assets"
env_aws_default_acl: ""
env_media_location: media/

# S3 bucket configuration:
k8s_s3_cluster_name: "{{ cluster_name }}"
k8s_s3_region: "{{ aws_region }}"
k8s_s3_public_bucket: "{{ k8s_s3_namespace }}-philly-assets"
k8s_s3_private_bucket: "{{ k8s_s3_namespace }}-philly-private-assets"

# Set up an AWS IAM user with limited perms for CI deploys
k8s_ci_username: hip-ci-user
k8s_ci_repository_arn: "arn:aws:ecr:us-east-1:061553509755:repository/philly-hip-stack-applicationrepository-kk92mehevd86"
k8s_ci_vault_password_arn: "arn:aws:secretsmanager:us-east-1:061553509755:secret:hip-ansible-vault-password-JYhbao"
